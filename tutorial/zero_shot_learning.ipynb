{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zero_shot_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfxTHWonV4_V",
        "outputId": "6e877fbb-3ee2-44d0-8545-7b8028501683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!git clone https://github.com/nageshsinghc4/deepwrap.git\n",
        "!cd deepwrap/\n",
        "#import os\n",
        "#os.chdir('/content/deepwrap/')\n",
        "#os.getcwd()\n",
        "#!pip install ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deepwrap'...\n",
            "remote: Enumerating objects: 273, done.\u001b[K\n",
            "remote: Counting objects: 100% (273/273), done.\u001b[K\n",
            "remote: Compressing objects: 100% (234/234), done.\u001b[K\n",
            "remote: Total 273 (delta 35), reused 254 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (273/273), 25.31 MiB | 31.60 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "Processing /content/deepwrap\n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAz7ZhzXSTiS"
      },
      "source": [
        "#Zero Shot Learning Using Natural Language Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbnToALmzB1a",
        "outputId": "00eb8e66-b8ea-44c3-8f9c-7f63a98a9b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/deepwrap/')\n",
        "os.getcwd()\n",
        "!pip install ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/deepwrap\n",
            "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (2.3.0)\n",
            "Collecting scipy==1.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/a8/f4c66eb529bb252d50e83dbf2909c6502e2f857550f22571ed8556f62d95/scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 117kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (1.1.2)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (1.0.0)\n",
            "Collecting keras_bert>=0.81.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (0.16.0)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (1.0.5)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (0.42.1)\n",
            "Collecting cchardet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/c5/7e1a0d7b4afd83d6f8de794fce82820ec4c5136c6d52e14000822681a842/cchardet-2.1.6-cp36-cp36m-manylinux2010_x86_64.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (2.5)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (2.1.1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/6c/71a5ca457851287ceba1c969bfb21f46ffdae7dfae1fa30456ef4bdc6412/seqeval-1.1.0.tar.gz\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (20.4)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (2.1.0)\n",
            "Collecting transformers>=2.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from DEEPWRAP==50.3.0) (5.5.0)\n",
            "Collecting syntok\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n",
            "Collecting whoosh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (0.35.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->DEEPWRAP==50.3.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->DEEPWRAP==50.3.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->DEEPWRAP==50.3.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->DEEPWRAP==50.3.0) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->DEEPWRAP==50.3.0) (2018.9)\n",
            "Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras_bert>=0.81.0->DEEPWRAP==50.3.0) (2.4.3)\n",
            "Collecting keras-transformer>=0.38.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->DEEPWRAP==50.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->DEEPWRAP==50.3.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->DEEPWRAP==50.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->DEEPWRAP==50.3.0) (3.0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.3->DEEPWRAP==50.3.0) (4.4.2)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->DEEPWRAP==50.3.0) (7.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->DEEPWRAP==50.3.0) (3.13)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh->DEEPWRAP==50.3.0) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh->DEEPWRAP==50.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->DEEPWRAP==50.3.0) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->DEEPWRAP==50.3.0) (0.24.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->DEEPWRAP==50.3.0) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->DEEPWRAP==50.3.0) (4.41.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->DEEPWRAP==50.3.0) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->DEEPWRAP==50.3.0) (0.3.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->DEEPWRAP==50.3.0) (20.2.0)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 48.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->DEEPWRAP==50.3.0) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->DEEPWRAP==50.3.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.11.0->DEEPWRAP==50.3.0) (0.7)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->DEEPWRAP==50.3.0) (50.3.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->DEEPWRAP==50.3.0) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->DEEPWRAP==50.3.0) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->DEEPWRAP==50.3.0) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->DEEPWRAP==50.3.0) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->DEEPWRAP==50.3.0) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->DEEPWRAP==50.3.0) (0.7.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (3.2.2)\n",
            "Collecting keras-pos-embd>=0.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.27.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->DEEPWRAP==50.3.0) (1.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->DEEPWRAP==50.3.0) (1.52.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.11.0->DEEPWRAP==50.3.0) (7.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->DEEPWRAP==50.3.0) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->DEEPWRAP==50.3.0) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->DEEPWRAP==50.3.0) (0.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (2.0.0)\n",
            "Collecting keras-self-attention==0.46.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->DEEPWRAP==50.3.0) (3.2.0)\n",
            "Building wheels for collected packages: DEEPWRAP, keras-bert, langdetect, seqeval, syntok, keras-transformer, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for DEEPWRAP (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DEEPWRAP: filename=DEEPWRAP-50.3.0-cp36-none-any.whl size=159940 sha256=76337c52af2d9f605a7420ba4d5f8c181e0f7d5c66a15a0c163f8d125bffeb69\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-26vj16y8/wheels/af/24/a8/dcb01380ee1bfb5222e1d610d7c073dceb7fe7e7152f037011\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34145 sha256=3e49b87859f4a4bb5f7bdc2e44f44076718731e1d1e91a49af7088284dacd008\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=1835309dda4d97e2b4b9ae15d7f780944464e972fe57f1c3cdf5f7d5a4816ebb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.1.0-cp36-none-any.whl size=14116 sha256=624ae1967f479d0eefb1a6e56b307577cae4a539e3d8d5de8544226a65c742ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/ba/2b/f4dd41aef3b9207cd61117ccccb055a6710b677ebbd33992d1\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-cp36-none-any.whl size=20919 sha256=2a53b1a54829e0877d360c6793a8766e6acce5246c625b6d8eed9f173a6fdb0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=542875a7bde00ea4abb4d6865c99ec795689a7a29874ce90e2d5b63359997a65\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=f33026727077b9ac0e4aae2aa71db93220afd57fc5638da34f6e6031720cc9b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=fc43d9f3a8565ad2eebd13bf9d12dd573e583d3c6c30cb4bd0626f83f15449f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=7046a526fd283ea26d737ea8eb2f00ebabf566bbbc89f80f4d9a6cb6d2d2e4c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=2f073844111251e81b3965d34f37b5324b7e3059db78811f541439902262e9b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5626 sha256=f17c3166dda09d2c28d48b421142b8ac8f7f42d48285203cd57d3b3ead337bee\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=f4209b57ba7f33995860d6a483e65858cac4c58814a97e1ca0efe5042a2d1fff\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=edce02221fb9d9afe7e6051d4928df5bf9becedf7fac0c8bcd8dd1f229de5b17\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
            "Successfully built DEEPWRAP keras-bert langdetect seqeval syntok keras-transformer sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.5.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seqeval 1.1.0 has requirement numpy==1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seqeval 1.1.0 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, seqeval, tokenizers, sacremoses, sentencepiece, transformers, syntok, whoosh, DEEPWRAP\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed DEEPWRAP-50.3.0 cchardet-2.1.6 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 langdetect-1.0.8 sacremoses-0.0.43 scipy-1.5.2 sentencepiece-0.1.91 seqeval-1.1.0 syntok-1.3.1 tokenizers-0.8.1rc2 transformers-3.3.1 whoosh-2.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p_5RsLPSQ5N"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN8jyGkXSdLT"
      },
      "source": [
        "In this notebook, we will demonstrate zero-shot topic classification. Zero-Shot Learning (ZSL) is being able to solve a task despite not having received any training examples of that task. The ZeroShotClassifier class in deepwrap can be used to perform topic classification with no training examples. The technique is based on Natural Language Inference (or NLI) as described in this interesting [blog post](https://joeddav.github.io/blog/2020/05/29/ZSL.html) by Joe Davison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agCZZ0MKSplX"
      },
      "source": [
        "####STEP 1: Setup the Zero Shot Classifier and Describe Topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DadQX7DaSsQZ"
      },
      "source": [
        "We first instantiate the zero-shot-classifier and then describe the topic labels for our classifier with strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzaGRNWcSchj"
      },
      "source": [
        "from deepwrap import text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHmHigRPSz0Y"
      },
      "source": [
        "zsl = text.ZeroShotClassifier()\n",
        "labels=['politics', 'elections', 'sports', 'films', 'television']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xclBavQS-kK"
      },
      "source": [
        "####STEP 2: Predict\n",
        "\n",
        "There is no training involved here, as we are using zero-shot-learning. We will simply supply the document that is being classified and the topic_strings defined earlier. The predict method uses Natural Language Inference (NLI) to infer the topic probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms-U_Ck9S20v",
        "outputId": "8dd42ed8-d02f-4a3c-ae3f-a40b05d14d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "doc = 'The only complaint about Avengers: Endgame is that it raises the bar so high that there may well never be a superhero movie to match it.'\n",
        "zsl.predict(doc, labels=labels, include_labels=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('politics', 0.006364297587424517),\n",
              " ('elections', 0.001596645568497479),\n",
              " ('sports', 0.0008818814530968666),\n",
              " ('films', 0.9753978252410889),\n",
              " ('television', 0.0010838382877409458)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-On2DUvTjRE"
      },
      "source": [
        "As you can see, our model correctly assigned the highest probabilities to films, as the text supplied pertains to that perticular topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDPhPhaoTrs5"
      },
      "source": [
        "Let's try some other examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rn0sckETfof",
        "outputId": "e4255259-fa82-4ee3-d79b-144e0c5fa5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "doc = 'What percentage of the ball hits the stumps doesn’t matter, if DRS shows us that the ball is hitting the stumps, it should be given out, regardless of the on-field call. That is the motive of using technology in Cricket. As we know technology isn’t 100% right but neither are humans'\n",
        "zsl.predict(doc, labels=labels, include_labels=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('politics', 0.0024332571774721146),\n",
              " ('elections', 0.002016625367105007),\n",
              " ('sports', 0.8952001333236694),\n",
              " ('films', 0.0014523775316774845),\n",
              " ('television', 0.17592257261276245)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdtwovodUVuC"
      },
      "source": [
        "**document about sports, television, and film**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHPXsYhpUCFQ",
        "outputId": "95a23d33-6eb6-40ba-c0a9-57f74d12125a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "doc ='The best sports documentaries tend to be made by US film-makers, about US sports and athletes and the way life seems sometimes to connect to those pastimes in a deeper, more profound way than in other countries, even in the UK. \\\n",
        "Despite the best efforts of the BBC, BT Sport and a couple of lone feature film-makers, in this game, we are playing catch-up.'\n",
        "zsl.predict(doc, labels=labels, include_labels=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('politics', 0.002238302491605282),\n",
              " ('elections', 0.0018134880810976028),\n",
              " ('sports', 0.9945294260978699),\n",
              " ('films', 0.7693668603897095),\n",
              " ('television', 0.9118184447288513)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otywztktU421"
      },
      "source": [
        "####Customizing the Classifier for Zero-Shot Sentiment Analysis\n",
        "\n",
        "As stated above, the ZeroShotClassifier is implemented using Natural Language Inference (NLI). That is, the document is treated as a premise, and each label is treated as a hypothesis. To predict labels, an NLI model is used to predict whether or not each label is entailed by the premise. By default, the template used for the hypothesis is of the form \"This text is about <label>.\", where <label> is replaced with a candidate label (e.g., politics, sports, etc.). Although this works well for many text classification problems such as the topic classification examples above, we can customize the template with the nli_template parameter if necessary. For instance, if predicting sentiment of movie reviews, we might change the template as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC0hlLyjUtvj",
        "outputId": "046f7a74-1984-46d1-a6bb-84a921b54acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc = \"Writer-director Rian Johnson establishes himself as an original talent who clearly believes storytelling must prevail.\"\n",
        "zsl.predict(doc, labels=['negative', 'positive'], include_labels=True,\n",
        "            nli_template=\"The sentiment of this movie review is {}.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('negative', 0.00380869023501873), ('positive', 0.9887452721595764)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvWE00MG_Pfk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
